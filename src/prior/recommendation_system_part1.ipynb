{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5687b43b",
   "metadata": {},
   "source": [
    "### Cell 1: Import Libraries and Setup\n",
    "\n",
    "**Markdown Explanation:**\n",
    "\n",
    "This cell is responsible for importing all the necessary Python libraries and setting up the initial environment for the recommendation system. The libraries include tools for data manipulation (`pandas`, `numpy`), visualization (`matplotlib`, `seaborn`), and machine learning (`surprise`, `sklearn`). It also sets up logging to capture critical errors only, and defines several constants that will be used throughout the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
    "import pandas as pd  # Data manipulation\n",
    "import numpy as np  # Numerical operations\n",
    "import logging  # Logging for debugging and error handling\n",
    "import itertools  # Handling iterators and combinations\n",
    "import re  # Regular expressions for string matching\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # Statistical data visualization\n",
    "import time  # Time utilities, used for calculating decay\n",
    "import warnings  # Suppress warnings to reduce unnecessary output\n",
    "from surprise import Dataset, Reader, SVD  # Surprise library for collaborative filtering\n",
    "from surprise.model_selection import train_test_split, GridSearchCV  # Model selection utilities for CF\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score  # Metrics for evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # Cosine similarity for content-based filtering\n",
    "from sklearn.preprocessing import StandardScaler  # Standard scaling of features\n",
    "from joblib import Parallel, delayed  # Parallel processing for efficiency\n",
    "\n",
    "# Suppress warnings related to deprecated or future features to keep the output clean\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Define constants that will be used throughout the recommendation system\n",
    "MOVIES_FILE = '../data/movies.csv'  # Path to the movies data file\n",
    "RATINGS_FILE = '../data/ratings.csv'  # Path to the ratings data file\n",
    "N_RECOMMENDATIONS = 5  # Number of recommendations to generate for each user\n",
    "YEAR_DIVISOR = 0.01  # Weighting factor that gives more importance to recent movies\n",
    "RATING_THRESHOLD = 4.0  # Minimum rating to consider a recommendation positive\n",
    "RANDOM_SEED = 42  # Seed for random number generators to ensure reproducibility\n",
    "USER_SAMPLE_SIZE = 500  # Number of users to sample for recommendations\n",
    "\n",
    "# Weights for hybrid scoring (combining CF and CBF approaches)\n",
    "CF_WEIGHT = 0.7  # Weight for collaborative filtering score\n",
    "CBF_WEIGHT = 0.3  # Weight for content-based filtering score\n",
    "POPULARITY_PENALTY_WEIGHT = 0.8  # Penalty weight for popular items to enhance diversity\n",
    "TIME_DECAY_FACTOR = 0.1  # Factor for time decay of ratings\n",
    "RECENCY_WEIGHT = 1.5  # Weight for recency factor in the hybrid score\n",
    "\n",
    "# Set random seed for numpy to ensure reproducibility of random operations\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Configure logging to capture only critical errors to reduce output verbosity\n",
    "logging.basicConfig(level=logging.ERROR,  # Set logging level to ERROR\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', \n",
    "                    handlers=[logging.FileHandler('recommendation_system.log'), logging.StreamHandler()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418a873-340f-4307-9805-d3f5be42ccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aa81b2d-15be-4164-8029-a9af5f1bb96b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cell 2: Data Loading and Preprocessing\n",
    "\n",
    "**Markdown Explanation:**\n",
    "\n",
    "This cell defines the function `load_data`, which is responsible for loading the movies and ratings data from CSV files, converting timestamps to datetime format, merging the datasets on the movie ID, extracting the release year from movie titles, and one-hot encoding genres. The function also includes error handling to log and raise exceptions if issues occur during data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e6883-5fe6-4c6c-928c-8cd530cde5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(movies_file, ratings_file):\n",
    "    \"\"\"\n",
    "    Load and preprocess movies and ratings data.\n",
    "\n",
    "    This function loads movie and rating data from CSV files, converts timestamps to datetime objects,\n",
    "    merges the data on movie IDs, extracts release years from titles, and one-hot encodes genres.\n",
    "\n",
    "    Parameters:\n",
    "        movies_file (str): Path to the movies data file.\n",
    "        ratings_file (str): Path to the ratings data file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three DataFrames (merged_df, movies_df, ratings_df)\n",
    "               - merged_df: DataFrame containing merged movies and ratings data with additional features.\n",
    "               - movies_df: DataFrame containing the original movies data.\n",
    "               - ratings_df: DataFrame containing the original ratings data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load movie data from CSV into a DataFrame\n",
    "        movies_df = pd.read_csv(movies_file)\n",
    "\n",
    "        # Load rating data from CSV into a DataFrame\n",
    "        ratings_df = pd.read_csv(ratings_file)\n",
    "\n",
    "        # Convert the timestamp column in ratings data to datetime format for easier manipulation\n",
    "        ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
    "\n",
    "        # Merge the movie and rating data on the movieId column to combine information from both datasets\n",
    "        merged_df = pd.merge(ratings_df, movies_df, on='movieId')\n",
    "\n",
    "        # Extract the release year from the title column using regular expressions, if not already present\n",
    "        if 'release_year' not in merged_df.columns:\n",
    "            merged_df['release_year'] = merged_df['title'].str.extract(r'\\((\\d{4})\\)')[0].astype(float)\n",
    "\n",
    "        # One-hot encode the genres by creating binary columns for each genre\n",
    "        genre_list = list(set(itertools.chain.from_iterable(merged_df['genres'].str.split('|'))))\n",
    "        for genre in genre_list:\n",
    "            genre_pattern = re.escape(genre)  # Escape genre name to handle special characters\n",
    "            merged_df[genre] = merged_df['genres'].str.contains(r'\\b' + genre_pattern + r'\\b').astype(int)\n",
    "\n",
    "        # Return the preprocessed DataFrames\n",
    "        return merged_df, movies_df, ratings_df\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        # Log an error if a file is not found and re-raise the exception\n",
    "        logging.error(f\"File not found: {fnf_error}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log any other exceptions that occur during data loading and re-raise the exception\n",
    "        logging.error(f\"Error loading data: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf14b02-5252-4367-ba18-712df9678b2d",
   "metadata": {},
   "source": [
    "### Cell 3: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Markdown Explanation:**\n",
    "\n",
    "This cell defines the function `perform_eda`, which performs exploratory data analysis on the merged movies and ratings data. It provides information about the dataset, visualizes the distribution of ratings, the number of ratings per movie and user, genre distribution, and the distribution of movie release years. It also calculates and displays a correlation matrix to understand relationships between different features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a117dfc-5165-4c13-9582-90dc30c39391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(merged_df):\n",
    "    \"\"\"\n",
    "    Perform Exploratory Data Analysis (EDA) on the merged movies and ratings data.\n",
    "\n",
    "    This function prints out information and displays plots to help understand the structure and distribution\n",
    "    of the merged movies and ratings data. Plots include distribution of ratings, number of ratings per movie,\n",
    "    number of ratings per user, genre distribution, and distribution of movie release years.\n",
    "    \"\"\"\n",
    "    # Display the first few rows of the merged DataFrame to understand its structure\n",
    "    print('Merged DataFrame:')\n",
    "    print(merged_df.head())\n",
    "\n",
    "    # Display the shape of the merged DataFrame to know the number of rows and columns\n",
    "    print('\\nShape of Merged DataFrame:', merged_df.shape)\n",
    "\n",
    "    # Display information about the merged DataFrame, including data types and non-null counts\n",
    "    print('\\nMerged DataFrame Info:')\n",
    "    print(merged_df.info())\n",
    "\n",
    "    # Display descriptive statistics of the merged DataFrame, such as mean, min, and max values\n",
    "    print('\\nMerged DataFrame Description:')\n",
    "    print(merged_df.describe())\n",
    "\n",
    "    # Check for missing values in each column of the merged DataFrame\n",
    "    print('\\nMissing Values in Merged DataFrame:')\n",
    "    print(merged_df.isnull().sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
